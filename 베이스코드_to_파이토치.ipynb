{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "베이스코드_to_파이토치.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOa2nKJhG31UoJntGM9uXxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junhyeongShin/colab/blob/main/%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%BD%94%EB%93%9C_to_%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyXaOg80n9lu"
      },
      "source": [
        "#텐서 차원 변경 할때 사용되는 메소드\n",
        "# torch.Size([4, 3, 32, 32])\n",
        "# train_t = np.transpose(train, (0, 2, 3, 1))\n",
        "# train_t.shape\n",
        "# torch.Size([4, 32, 32, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpxeuDm_VBeq"
      },
      "source": [
        "# torch 임포트 다운로드\n",
        "\n",
        "pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6po_YgOXT5_Q"
      },
      "source": [
        "pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDgp9JOMT702"
      },
      "source": [
        "pip install Pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YYaFPtIVDmV"
      },
      "source": [
        "\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtCYxvucVDof"
      },
      "source": [
        "# 구글 드라이브에 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# 해당폴더로 이동\n",
        "%cd drive/My\\ Drive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxv74VjFVKaH"
      },
      "source": [
        "data_path = './data_v2/'\n",
        "train_data_path = os.path.join(data_path, \"train_data_v2\")\n",
        "print(train_data_path)\n",
        "file_list = os.listdir(train_data_path)\n",
        "file_list.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wybJIAEEaSDh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torchvision import transforms, utils\n",
        "from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = None\n",
        "# gpu 사용\n",
        "if torch.cuda.is_available() :\n",
        "    device = torch.device('cuda')\n",
        "else : \n",
        "    device = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbFqfO56Wa1X"
      },
      "source": [
        "path = data_path\n",
        "train_csv = pd.read_csv(path+'train_v2.csv')\n",
        "train_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "722xvaEBa5Rl"
      },
      "source": [
        "train_path = sorted(glob(path+'train_data_v2/*.npy'))\n",
        "train_path = train_path[-30*12:]\n",
        "\n",
        "train = []\n",
        "for p in tqdm(train_path):\n",
        "    # train.append(np.load(p))\n",
        "    tmp = np.load(p)\n",
        "    # tmp[:,:,0] = tmp[:,:,0]/250\n",
        "    train.append(tmp)\n",
        "    # (360, 448, 304, 5)\n",
        "train = np.array(train)\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dShL5dtna5T6"
      },
      "source": [
        "train_month = []\n",
        "for i in range(12):\n",
        "    train_month.append(train[i::12, :,:])\n",
        "train_month = np.array(train_month)\n",
        "\n",
        "train_month.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQ-TBu-a5V7"
      },
      "source": [
        "stride = 64\n",
        "temp = np.zeros([train_month.shape[0],\n",
        "                 train_month.shape[1],\n",
        "                 train_month.shape[2]+(stride-train_month.shape[2]%stride),\n",
        "                 train_month.shape[3]+(stride-train_month.shape[3]%stride),\n",
        "                 train_month.shape[4]], np.uint8)\n",
        "temp[:, :,:train_month.shape[2], :train_month.shape[3], :] = train_month\n",
        "train_month = temp\n",
        "del temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVWWmEgcDYd2"
      },
      "source": [
        "window_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r5W57S0DYgo"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(train_month.shape[1]-window_size):\n",
        "    x_train.append(train_month[:, i:i+window_size, :,:,:])\n",
        "    y_train.append(train_month[:, i+window_size:i+window_size+1, :,:,:])\n",
        "    \n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BchvaHPvDYjb"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z261CkgwDYl2"
      },
      "source": [
        "#stride = 32\n",
        "feature_size = 128\n",
        "x_train_ = []\n",
        "y_train_ = []\n",
        "for y in range(x_train.shape[0]):\n",
        "    for m in range(12):\n",
        "        for i in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "            for j in range((x_train.shape[4]-feature_size)//stride+1):\n",
        "                x_ = x_train[y, m, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size, :1]\n",
        "                y_ = y_train[y, m, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size, :1]\n",
        "                x_train_.append(x_)\n",
        "                y_train_.append(y_)\n",
        "\n",
        "x_train_ = np.array(x_train_)\n",
        "y_train_ = np.array(y_train_)\n",
        "\n",
        "x_val_ = []\n",
        "y_val_ = []\n",
        "\n",
        "for m in range(12):\n",
        "    for i in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "        for j in range((x_train.shape[4]-feature_size)//stride+1):\n",
        "            x_ = x_train[-1, m, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size, :1]\n",
        "            y_ = y_train[-1, m, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size, :1]\n",
        "            x_val_.append(x_)\n",
        "            y_val_.append(y_)\n",
        "            \n",
        "x_val_ = np.array(x_val_)\n",
        "y_val_ = np.array(y_val_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Yr5uWzDYoN"
      },
      "source": [
        "x_train_.shape, y_train_.shape, x_val_.shape, y_val_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOFmQk3DYqy"
      },
      "source": [
        "# 데이터 이미지 확인\n",
        "i = 38\n",
        "plt.figure(figsize=(15,10))\n",
        "for y in range(x_train_.shape[1]):\n",
        "    plt.subplot(1,window_size,y+1)\n",
        "    plt.imshow(x_train_[i,y,:,:,0])\n",
        "plt.show()\n",
        "plt.imshow(y_train_[i,-1,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j653E_Zb2Oe2"
      },
      "source": [
        "# 데이터 셋 구성부분입니다.\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, train_x,train_y):\n",
        "        super(TrainDataset, self).__init__()\n",
        "\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        # self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터 갯수\n",
        "        return self.train_x.shape[0]\n",
        "    \n",
        "\n",
        "    # 데이터를 들고올때 이미지를 잘라서 필요한 갯수만큼 들고올수 있도록 설정해 놓았기때문에\n",
        "    # 해당 부분에서는 넘파이를 탠서로 변경해주고있습니다.\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = self.train_x[idx]\n",
        "        y = self.train_y[idx]\n",
        "\n",
        "        #torch를 사용해서 탠서로 변경해줍니다. 탠서의 자료형은 float입니다.\n",
        "        x = torch.tensor(x)\n",
        "        x = torch.FloatTensor(x/250)\n",
        "\n",
        "        # 모델에 넣어줄때 필요한 순서를 맞추기 위해서\n",
        "        # 탠서 차원 순서를 변경해주고 있습니다.\n",
        "        # ex) y = x.permute (1,0) => y의 1번째 차원에 x의 0번째 차원으로 변경하겠다.\n",
        "        x = x.permute(0,3,2,1)\n",
        "        x = x.permute(1,0,2,3)\n",
        "        # 5, 128, 128, 1\n",
        "\n",
        "        y = torch.tensor(y)\n",
        "        y = torch.FloatTensor(y/250)\n",
        "        y = y.permute(0,3,2,1)\n",
        "        y = y.permute(1,0,2,3)\n",
        "\n",
        "        return x,y\n",
        "\n",
        "\n",
        "\n",
        "# def getTransform():\n",
        "#     return transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# transform = getTransform()\n",
        "\n",
        "#데이터 로더에서 자료 가져올때 \n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# train_dataset = TrainDataset(x_train_,y_train_,transform)\n",
        "# valid_dataset = TrainDataset(x_val_,y_val_,transform)\n",
        "\n",
        "train_dataset = TrainDataset(x_train_,y_train_)\n",
        "valid_dataset = TrainDataset(x_val_,y_val_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqQPz80diFjV"
      },
      "source": [
        "# Dataloader 클래스는 데이터셋에서 배치 개수만큼 뽑아서 제공해줍니다\n",
        "# 데이터 로더는 torch에서 제공해주는 기본 클래스를 사용했습니다.\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=2, prefetch_factor=2)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=2, prefetch_factor=2)\n",
        "\n",
        "\n",
        "# 데이터 로더에서 가져오는 데이터의 모양 확인\n",
        "for x, y in train_dataloader:\n",
        "    print(x.shape, y.shape)\n",
        "    break\n",
        "\n",
        "    # (samples, time, rows, cols, channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SISPlU6wj4i"
      },
      "source": [
        "# convlstm 예제입니다.\n",
        "\n",
        "# import torch.nn as nn\n",
        "# import torch\n",
        "\n",
        "\n",
        "# class ConvLSTMCell(nn.Module):\n",
        "\n",
        "#     def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
        "#         \"\"\"\n",
        "#         Initialize ConvLSTM cell.\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         input_dim: int\n",
        "#             Number of channels of input tensor.\n",
        "#         hidden_dim: int\n",
        "#             Number of channels of hidden state.\n",
        "#         kernel_size: (int, int)\n",
        "#             Size of the convolutional kernel.\n",
        "#         bias: bool\n",
        "#             Whether or not to add the bias.\n",
        "#         \"\"\"\n",
        "\n",
        "#         super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "#         self.input_dim = input_dim\n",
        "#         self.hidden_dim = hidden_dim\n",
        "\n",
        "#         self.kernel_size = kernel_size\n",
        "#         self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "#         self.bias = bias\n",
        "\n",
        "#         self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "#                               out_channels=4 * self.hidden_dim,\n",
        "#                               kernel_size=self.kernel_size,\n",
        "#                               padding=self.padding,\n",
        "#                               bias=self.bias)\n",
        "\n",
        "#     def forward(self, input_tensor, cur_state):\n",
        "#         h_cur, c_cur = cur_state\n",
        "\n",
        "#         combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "\n",
        "#         combined_conv = self.conv(combined)\n",
        "#         cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "#         i = torch.sigmoid(cc_i)\n",
        "#         f = torch.sigmoid(cc_f)\n",
        "#         o = torch.sigmoid(cc_o)\n",
        "#         g = torch.tanh(cc_g)\n",
        "\n",
        "#         c_next = f * c_cur + i * g\n",
        "#         h_next = o * torch.tanh(c_next)\n",
        "\n",
        "#         return h_next, c_next\n",
        "\n",
        "#     def init_hidden(self, batch_size, image_size):\n",
        "#         height, width = image_size\n",
        "#         return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "#                 torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXgpL1eKbIo"
      },
      "source": [
        "# pytorch convlstm 예제중 사용해보던 모델입니다.\n",
        "\n",
        "# class EncoderDecoderConvLSTM(nn.Module):\n",
        "#     def __init__(self, nf, in_chan):\n",
        "#         super(EncoderDecoderConvLSTM, self).__init__()\n",
        "\n",
        "#         \"\"\" ARCHITECTURE \n",
        "\n",
        "#         # Encoder (ConvLSTM)\n",
        "#         # Encoder Vector (final hidden state of encoder)\n",
        "#         # Decoder (ConvLSTM) - takes Encoder Vector as input\n",
        "#         # Decoder (3D CNN) - produces regression predictions for our model\n",
        "\n",
        "#         \"\"\"\n",
        "#         self.encoder_1_convlstm = ConvLSTMCell(input_dim=in_chan,\n",
        "#                                                hidden_dim=nf,\n",
        "#                                                kernel_size=(3, 3),\n",
        "#                                                bias=True)\n",
        "\n",
        "#         self.encoder_2_convlstm = ConvLSTMCell(input_dim=nf,\n",
        "#                                                hidden_dim=nf,\n",
        "#                                                kernel_size=(3, 3),\n",
        "#                                                bias=True)\n",
        "\n",
        "#         self.decoder_1_convlstm = ConvLSTMCell(input_dim=nf,  # nf + 1\n",
        "#                                                hidden_dim=nf,\n",
        "#                                                kernel_size=(3, 3),\n",
        "#                                                bias=True)\n",
        "\n",
        "#         self.decoder_2_convlstm = ConvLSTMCell(input_dim=nf,\n",
        "#                                                hidden_dim=nf,\n",
        "#                                                kernel_size=(3, 3),\n",
        "#                                                bias=True)\n",
        "\n",
        "#         self.decoder_CNN = nn.Conv3d(in_channels=nf,\n",
        "#                                      out_channels=1,\n",
        "#                                      kernel_size=(1, 3, 3),\n",
        "#                                      padding=(0, 1, 1))\n",
        "\n",
        "\n",
        "#     def autoencoder(self, x, seq_len, future_step, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4):\n",
        "\n",
        "#         outputs = []\n",
        "\n",
        "#         # encoder\n",
        "#         for t in range(seq_len):\n",
        "#             h_t, c_t = self.encoder_1_convlstm(input_tensor=x[:, t, :, :],\n",
        "#                                                cur_state=[h_t, c_t])  # we could concat to provide skip conn here\n",
        "#             h_t2, c_t2 = self.encoder_2_convlstm(input_tensor=h_t,\n",
        "#                                                  cur_state=[h_t2, c_t2])  # we could concat to provide skip conn here\n",
        "\n",
        "#         # encoder_vector\n",
        "#         encoder_vector = h_t2\n",
        "\n",
        "#         # decoder\n",
        "#         for t in range(future_step):\n",
        "#             h_t3, c_t3 = self.decoder_1_convlstm(input_tensor=encoder_vector,\n",
        "#                                                  cur_state=[h_t3, c_t3])  # we could concat to provide skip conn here\n",
        "#             h_t4, c_t4 = self.decoder_2_convlstm(input_tensor=h_t3,\n",
        "#                                                  cur_state=[h_t4, c_t4])  # we could concat to provide skip conn here\n",
        "#             encoder_vector = h_t4\n",
        "#             outputs += [h_t4]  # predictions\n",
        "\n",
        "#         outputs = torch.stack(outputs, 1)\n",
        "#         outputs = outputs.permute(0, 2, 1, 3, 4)\n",
        "#         outputs = self.decoder_CNN(outputs)\n",
        "#         outputs = torch.nn.Sigmoid()(outputs)\n",
        "\n",
        "#         return outputs\n",
        "\n",
        "#     def forward(self, x, future_seq=0, hidden_state=None):\n",
        "\n",
        "#         \"\"\"\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         input_tensor:\n",
        "#             5-D Tensor of shape (b, t, c, h, w)        #   batch, time, channel, height, width\n",
        "#         \"\"\"\n",
        "\n",
        "#         # find size of different input dimensions\n",
        "#         b, seq_len, _, h, w = x.size()\n",
        "\n",
        "#         # initialize hidden states\n",
        "#         h_t, c_t = self.encoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "#         h_t2, c_t2 = self.encoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "#         h_t3, c_t3 = self.decoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "#         h_t4, c_t4 = self.decoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "\n",
        "#         # autoencoder forward\n",
        "#         outputs = self.autoencoder(x, seq_len, future_seq, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4)\n",
        "\n",
        "#         return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpkOduzoP9Ti"
      },
      "source": [
        "# 공부하던 예제입니다.\n",
        "\n",
        "# class test_Net(nn.Module): # nn.Module 모든 신경망 모듈의 기본이 되는 클래스\n",
        "#                       # 각 층과 함수 등 신경망의 구성요소를 이 클래스 안에서 정의한다.\n",
        "#                       # nn.Module은 모든 신경망 모듈의 기본이 되는 클래스로 레이어, 함수등을 정의하는구나!\n",
        "\n",
        "#     def __init__(self):  # 초기화 함수   \n",
        "#         super(test_Net, self).__init__()\n",
        "\n",
        "#         self.convlstm1 = ConvLSTMCell(1, 64, (3,3),bias=True)  \n",
        "#         self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "#         # self.convlstm2 = ConvLSTM(128,128,(3,3),1,bias=True)     \n",
        "#         # self.batchnorm2 = nn.BatchNorm2d(1)\n",
        "#         # self.convlstm3 = ConvLSTM(128,128,(3,3),1,bias=True)   \n",
        "#         # self.batchnorm3 = nn.BatchNorm2d(1) \n",
        "\n",
        "#         self.conv4 = nn.Conv3d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.convlstm1(x)\n",
        "#         print(type(x))\n",
        "#         print(len(x))\n",
        "\n",
        "#         x = torch.tensor(x)\n",
        "#         print(x.size())\n",
        "#         x = self.batchnorm1(x)\n",
        "#         # x = self.convlstm2(x)\n",
        "#         # x = self.batchnorm2(x)        \n",
        "#         # x = self.convlstm3(x)\n",
        "#         # x = self.batchnorm3(x)\n",
        "#         # print(x.size())\n",
        "#         x = self.conv4(torch.tensor(x))\n",
        "\n",
        "#         return x     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjNqLK_DEp4I"
      },
      "source": [
        "# channels = 1\n",
        "# model = ConvLSTM(input_dim=channels,\n",
        "#                  hidden_dim=[64, 64, 128],\n",
        "#                  kernel_size=(3, 3),\n",
        "#                  num_layers=3,\n",
        "#                  batch_first=True,\n",
        "#                  bias=True,\n",
        "#                  return_all_layers=False).to(device)\n",
        "# model = EncoderDecoderConvLSTM().to(device)\n",
        "\n",
        "\n",
        "#모델을 생성해주고 cuda 를 사용하게끔 설정해줍니다.\n",
        "model = test_Net().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji_2bTVaql7P"
      },
      "source": [
        "# Loss Function && etric Function\n",
        "# 대회에서 제공해주던 산식코드입니다. 250으로 나눠준 상태입니다.\n",
        "\n",
        "# metrics\n",
        "def mae_score(true, pred):\n",
        "    true, pred = numpy_to_tensor(true, pred)\n",
        "    score = np.mean(np.abs(true-pred))\n",
        "    \n",
        "    return score\n",
        "\n",
        "# metrics\n",
        "def f1_score(true, pred):\n",
        "    true, pred = numpy_to_tensor(true, pred)\n",
        "\n",
        "    target = np.where((true>1*0.05)<1*0.5)\n",
        "    \n",
        "    true = true[target]\n",
        "    pred = pred[target]\n",
        "    true = np.where(true < 1*0.15, 0, 1)\n",
        "    pred = np.where(pred < 1*0.15, 0, 1)\n",
        "    \n",
        "    \n",
        "    right = np.sum(true * pred == 1)\n",
        "    precision = right / np.sum(true+1e-8)\n",
        "    recall = right / np.sum(pred+1e-8)\n",
        "    score = 2 * precision*recall/(precision+recall+1e-8)\n",
        "    \n",
        "    return score\n",
        "    \n",
        "# loss function\n",
        "def mae_over_f1(true, pred):\n",
        "    mae = mae_score(true, pred)\n",
        "    f1 = f1_score(true, pred)\n",
        "    score = mae/(f1+1e-8)\n",
        "    \n",
        "    return score\n",
        "\n",
        "def numpy_to_tensor(true, pred):\n",
        "\n",
        "    return true.cpu().numpy().argmax(), pred.cpu().numpy().argmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYyMbP6DsZj"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "# adam optimizer\n",
        "# 옵티아미저 상세 설정 부분입니다.\n",
        "opt_adam = optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "#현재 학습률을 나타내기위한 함수입니다.\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group[\"lr\"]\n",
        "\n",
        "# check our learning rate\n",
        "current_lr = get_lr(opt_adam)\n",
        "print(f\"current_lr = {current_lr}\")\n",
        "\n",
        "\n",
        "\n",
        "# learning rate scheduler\n",
        "# 학습에 도움을주는 스케쥴러 입니다.\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\n",
        "\n",
        "# example \n",
        "# 학습에따른 학습률 감소를 보여줍니다.\n",
        "for i in range(100):\n",
        "    lr_scheduler.step(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyfGxXEDscA"
      },
      "source": [
        "# Training \n",
        "\n",
        "def metrics_batch(pred, true, metrics):\n",
        "    # if needed add param \"metrics\" to custom\n",
        "    \"\"\"\n",
        "    output will be pred\n",
        "    target will be corrects\n",
        "    \"\"\"\n",
        "    if metrics:\n",
        "        return list(map(lambda x: x(true, pred), metrics))\n",
        "    mae_score = mae_score(true, pred)\n",
        "    f1_score = f1_score(true, pred)\n",
        "    return (mae_score, f1_score)\n",
        "\n",
        "def loss_batch(loss_func, pred, true, opt=None):\n",
        "    \"\"\"\n",
        "    loss_func => mae_over_f1\n",
        "    \"\"\"\n",
        "    loss = loss_func(true, pred)\n",
        "    with torch.no_grad():\n",
        "        metrics = metrics_batch(pred, true, [mae_score, f1_score])\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        # loss.backward()\n",
        "        opt.step()  # 학습이 이뤄지는 곳\n",
        "    return loss, metrics\n",
        "\n",
        "def loss_epoch(model, loss_func, dataset_dataloader, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = [0.0, 0.0]\n",
        "    len_data = len(dataset_dataloader.dataset)\n",
        "\n",
        "    for x, y in dataset_dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # 모델 결과\n",
        "        pred = model(x)\n",
        "        # 손실함수 구하기\n",
        "        loss, metrics = loss_batch(loss_func, pred, y, opt)\n",
        "        # 손실함수 \n",
        "        running_loss += loss\n",
        "        if metrics is not None:\n",
        "            for idx, metric_value in enumerate(metrics):\n",
        "                running_metric[idx] += metric_value\n",
        "        \n",
        "        # 문제 있으면 break, 여기서는 True 일때 바로 break\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "    \n",
        "    loss = running_loss / float(len_data)\n",
        "    metrics = list(map(lambda x: x/float(len_data), metrics))\n",
        "    print(loss, metrics)\n",
        "    return loss, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL6f978Bq4Vs"
      },
      "source": [
        "# pytorch 기본코드에서 제작한 로스값 입니다.\n",
        "loss_func = mae_over_f1\n",
        "\n",
        "opt_adam = optim.Adam(model.parameters(), lr=3e-4)\n",
        "# lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\n",
        "\n",
        "#학습에 필요한 파라미터들을 한번에 정리하고\n",
        "#학습 메소드에 넣어줍니다.\n",
        "TRAIN_PARAMS = {\n",
        "    \"num_epochs\" : 10,\n",
        "    \"loss_func\" : loss_func,\n",
        "    \"optimizer\" : opt_adam,\n",
        "    \"train_dataloader\" : train_dataloader,\n",
        "    \"valid_dataloader\" : valid_dataloader,\n",
        "    \"sanity_check\" : True,\n",
        "    \"lr_scheduler\" : lr_scheduler,\n",
        "    \"save_path\" : \"./weights.pt\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYRYUBvxq4Ts"
      },
      "source": [
        "import copy\n",
        "\n",
        "def train(model, params):\n",
        "    num_epochs = params['num_epochs']\n",
        "    loss_func = params['loss_func']\n",
        "    opt = params[\"optimizer\"]\n",
        "    train_dataloader = params['train_dataloader']\n",
        "    valid_dataloader = params['valid_dataloader']\n",
        "    sanity_check = params['sanity_check']\n",
        "    lr_scheduler = params['lr_scheduler']\n",
        "    save_path = params['save_path']\n",
        "\n",
        "    # keep history of the loss and metric\n",
        "    loss_hist = {\n",
        "        \"train\" : [],\n",
        "        \"valid\" : []\n",
        "    }\n",
        "\n",
        "    metrics_hist = {\n",
        "        \"train\" : [],\n",
        "        \"valid\" : []\n",
        "    }\n",
        "\n",
        "    # copy best weights\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    # init best loss\n",
        "    # 최저 로스값을 가져옵니다.\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    #측정 할때는 반복문을 없애고 eval 로만 진행해야합니다.\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print(f'Epoch:{epoch}/{num_epochs-1}, current lr:{current_lr}')\n",
        "        model.train()\n",
        "        train_loss, train_metrics = loss_epoch(model, loss_func, train_dataloader, sanity_check, opt)\n",
        "\n",
        "        # save history\n",
        "        loss_hist[\"train\"].append(train_loss)\n",
        "        metrics_hist[\"train\"].append(train_metrics)\n",
        "\n",
        "        \n",
        "        # model.eval()\n",
        "        # with torch.no_grad():\n",
        "    \n",
        "\n",
        "    return model, loss_hist, metrics_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzQVLK8pq4RM"
      },
      "source": [
        "\n",
        "\n",
        "my_model, loss_hist, metrics_hist = train(model, TRAIN_PARAMS)\n",
        "\n",
        "print(loss_hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqdtItYp9DI0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apnBw_Isi6FJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}